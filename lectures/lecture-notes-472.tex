\documentclass[10pt]{article}
% Math Packages
\usepackage{float} % Required to use [H]
\usepackage{amsmath, mathtools}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{breqn}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}
\usepackage{forest}
\usepackage{tikz-qtree}
\graphicspath{ {./images/} }
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\usepackage[shortlabels]{enumitem}
\usetikzlibrary{arrows,matrix,positioning}
\usepackage{multicol}

\usepackage{mathtools}% http://ctan.org/pkg/mathtools
\usepackage{abraces} %xyz



\usepackage{empheq} % for boxed equations
\usepackage[most]{tcolorbox}
\newtcbox{\mymath}[1][]{%
  nobeforeafter, math upper, tcbox raise base,
  enhanced, colframe=blue!30!black,
  colback=blue!30, boxrule=1pt,
  #1}
\newtcbox{\boxmath}[1][]{%
  nobeforeafter, math upper, tcbox raise base,
  enhanced, colframe=blue!30!black,
  boxrule=1pt,
  #1}

% for the pipe symbol
\usepackage[T1]{fontenc}


% Citing theorems by name. (source: https://tex.stackexchange.com/questions/109843/cleveref-and-named-theorems)
\makeatletter
\newcommand{\ncref}[1]{\cref{#1}\mynameref{#1}{\csname r@#1\endcsname}}

\def\mynameref#1#2{%
  \begingroup
  \edef\@mytxt{#2}%
  \edef\@mytst{\expandafter\@thirdoffive\@mytxt}%
  \ifx\@mytst\empty\else
  \space(\nameref{#1})\fi
  \endgroup
}
\makeatother

% Colorful Notes
\usepackage{color} \definecolor{Red}{rgb}{1,0,0} \definecolor{Blue}{rgb}{0,0,1}
\definecolor{Purple}{rgb}{.5,0,.5} \def\red{\color{Red}} \def\blue{\color{Blue}}
\def\gray{\color{gray}} \def\purple{\color{Purple}}
\newcommand{\rnote}[1]{{\red [#1]}} % \rnote{foo} gives '[foo]' in red
\newcommand{\pnote}[1]{{\purple [#1]}} % \pnote{foo} gives '[foo]' in purple
\newcommand{\bnote}[1]{{\blue #1}} % \bnote{foo} gives 'foo' in blue
\newcommand{\gnote}[1]{{\gray #1}} % \gnote{foo} gives 'foo' in gray
\newcommand{\Max}[1]{{\purple [#1]}} % \bnote{foo} then 'foo' is blue


% Claim numbering (the counter restarts after each proof environment)
\newcounter{claimcount}
\setcounter{claimcount}{0}
\newenvironment{claim}{\refstepcounter{claimcount}\par\addvspace{\medskipamount}\noindent\textbf{Claim \arabic{claimcount}:}}{}
\usepackage{etoolbox}
\AtBeginEnvironment{proof}{\setcounter{claimcount}{0}}
\newenvironment{claimproof}{\par\addvspace{\medskipamount}\noindent\textit{Proof of Claim  \arabic{claimcount}.}}{\hfill\ensuremath{\qedsymbol} \tiny{Claim}

  \medskip}
% Add claim support to cleverref
\crefname{claimcount}{Claim}{Claims}


% Math Environments
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{question}[theorem]{Question}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}


\usepackage{skull}

% Redefine the Example environment to include "End of example [number]"
\makeatletter
\let\oldexample\example
\renewenvironment{example}
{\begin{oldexample}}
  {\par\smallskip\hfill   End of Example~\theexample. $\square$    \par\end{oldexample}}
\makeatother


% Matrices and Column Vectors. 
\usepackage{stackengine}
\setstackgap{L}{1.0\normalbaselineskip}
\usepackage{tabstackengine}
\setstackEOL{;}% row separator
\setstackTAB{,}% column separator
\setstacktabbedgap{1ex}% inter-column gap
\setstackgap{L}{1.5\normalbaselineskip}% inter-row baselineskip
\let\nmatrix\bracketMatrixstack  %Usage: \nmatrix{1,2,3\4,5,6}
\newcommand\cv[1]{\setstackEOL{,}\bracketMatrixstack{#1}} %usage: \cv{1,2,3}

% Custom Math Coqmmands
\newcommand{\vt}{\vskip 5mm} % vertical space
\newcommand{\fl}{\noindent\textbf} % first line
\newcommand{\Fl}{\vt\noindent\textbf} % first line with space above
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % norm
\newcommand{\pnorm}[1]{\left\lVert#1\right\rVert_p} % p-norm
\newcommand{\qnorm}[1]{\left\lVert#1\right\rVert_q} % q-norm
\newcommand{\1}[1]{\textbf{1}_{\left[#1\right]}} % indicator function 
\def\limn{\lim_{n\to\infty}} % shortcut for lim as n-> infinity
\def\sumn{\sum_{n=1}^{\infty}} % shortcut for sum from n=1 to infinity
\def\sumkn{\sum_{k=1}^{n}} % shortcut for sum from k=1 to n
\def\sumin{\sum_{i=1}^{n}} % shortcut for sum from i=1 to n
\def\SAs{\sigma\text{-algebras}} % shortcut for $\sigma$-algebras
\def\SA{\sigma\text{-algebra}} % shortcut for $\sigma$-algebra
\def\Ft{\mathcal{F}_t} % time-indexed sigma-algebra (t)
\def\Fs{\mathcal{F}_s} % time-indexed sigma-algebra (s)
\def\F{\mathcal{F}} % sigma-algebra
\def\G{\mathcal{G}} % sigma-algebra
\def\R{\mathbb{R}} % Real numbers
\def\N{\mathbb{N}} % Natural numbers
\def\Z{\mathbb{Z}} % Integers
\def\E{\mathbb{E}} % Expectation
\def\P{\mathbb{P}} % Probability
\def\Q{\mathbb{Q}} % Q probability
\def\dist{\text{dist}} %Text 'dist' for things like 'dist(x,y)'
\newcommand{\indep}{\perp \!\!\! \perp}  %independence symbol
\def\Var{\mathrm{Var}} % Variance
\def\tr{\mathrm{tr}} % trace

% Brackets and Parentheses
\def\[{\left [}
    \def\]{\right ]}
% \def\({\left (}
%   \def\){\right )}




\usepackage{color}
\definecolor{Red}{rgb}{1,0,0}
\definecolor{Blue}{rgb}{0,0,1}
\definecolor{Purple}{rgb}{.5,0,.5}
\def\red{\color{Red}}
\def\blue{\color{Blue}}
\def\gray{\color{gray}}
\def\purple{\color{Purple}}
\definecolor{RoyalBlue}{cmyk}{1, 0.50, 0, 0}
\newcommand{\dempfcolor}[1]{{\color{RoyalBlue}#1}} 
\newcommand{\demph}[1]{\textcolor{RoyalBlue}{\textbf{\slshape #1}}} % Slanted
% RoyalBlue text

% comment exactly one of the following line to show / hide the solutions
% \newcommand{\solution}[1]{{\purple #1}} % uncomment to show the solutions
\newcommand{\solution}[1]{} % uncomment to hide the solutions



\title{Lecture Notes for Math 372: \\Elementary Probability and Statistics}
\date{Last updated: \today}
% \author{mh}

\begin{document}
\maketitle




\tableofcontents
\newpage
\setcounter{section}{-1}
\section{Tentative course outline}

This course is a problem-oriented introduction to the basic concepts of probability and statistics,
providing a foundation for applications and further study.
\begin{enumerate}
  \item \textbf{Weeks 1-2.} Sampling distributions (4 lessons).

  chi-squared, t, and F distributions, distributions of sample mean and
  variance

  \item \textbf{Weeks 3-4.} Point estimation (5 lessons)

  properties and methods of point estimation

  \item \textbf{Weeks 5-6.} Interval estimation (4 lessons)

  Confidence intervals for means, variances, proportions and differences

  \item \textbf{Weeks 7-12.} Hypothesis Testing (19 lessons)

  Neyman-Pearson lemma, likelihood ratio test; tests concerning means and
  variances, tests based on count data, nonparametric tests, analysis of variance

  \item \textbf{Weeks 13-14.} Regression and correlation (6 lessons)

  regression, bivariate normal distributions, method of least squares
\end{enumerate}



\newpage
\section{2025-01-12 | Week 01 |  Lecture 01}

\begin{itemize}
  \item give syllabus
  \item do activity with why you're in this course
\end{itemize}


\begin{center}
  \begin{tcolorbox}[width=0.9\textwidth, colback=white, colframe=black]
    \textit{\textbf{The nexus question of this lecture:} What is a
      probability?}
  \end{tcolorbox}
\end{center}
\textbf{Reading assignment:} Sections 1.1, 1.2, 1.3, 2.1, 2.4 of the textbook.

\subsection{What is probability?}
\subsubsection{A general framework: sample space, events, etc}
We begin with a general framework and some terminology to formalize the
notions of probability. This is based on section 2.4 in the textbook.

\begin{itemize}
  \item An \demph{experiment} is an activity or process whose outcome is
  subject to uncertainty, and about which an observation is made.

  Examples include flipping a coin, rolling a dice, measuring the size of a
  wave, or the amount of rainfall, conducting a poll, performing a diagnostic
  test, opening a pack of Pokemon cards, etc.

  \item The \demph{sample space} $S$ of an experiment is the set of all
  possible outcomes. The elements of the sample space are called \demph{sample
    points}.

  We think of each sample point as representing a unique outcome of the
  experiment. In the case of rolling a dice, the sample points are $1,2,3,4,5$
  and $6$, and the sample space is $S=\left\{1,2,3,4,5,6\right\}$.


  \item We use the term \demph{event} to refer to a collection of
  outcomes, i.e., a subset of $S$.

  Example: if our experiment is rolling a 6-sided dice, here are some events

  \begin{equation*}
    \begin{aligned}
      A &= [\text{observe an odd number}]\\
      B &= [\text{observe an even number}]\\
      C &= [\text{observe a number less than 5}]\\
      D &= [\text{observe a 2 or a 3}]\\
      E_1 &= [\text{observe a 1}]
    \end{aligned}
    \qquad
    \begin{aligned}
      E_2 &= [\text{observe a 2}]\\
      E_3 &= [\text{observe a 3}]\\
      E_4 &= [\text{observe a 4}]\\
      E_5 &= [\text{observe a 5}]\\
      E_6 &= [\text{observe a 6}]
    \end{aligned}
  \end{equation*}

  \item There are two types of events: \demph{compound events}, which can be
  decomposed into other events, and \demph{simple events}, which cannot.

  In the above example, the events $A,B,C$ and $D$ are compound events. $E_{1},\ldots,E_{6}$ are simple events.

  \item A sample space is \demph{discrete} if it is countable (i.e., finite or
  countably infinite). In a discrete sample space $S$, the set of all possible
  events is the \textit{power set} of $S$.\footnote{If $S$ is not discrete, a
    complication arises: in that case, some subsets of $S$ are too wild and
    untameable for us to treat them mathematically as ``events''. Resolving
    that issue requires introducing measure theory, which is beyond the scope
    of this class, so we will ignore it and simply steer clear of any setting
    where any issues might arise.}

  In the dice-rolling example, the set of all possible events is
  $\left\{E: E\subseteq \left\{1,2,3,4,5,6\right\} \right\}$. 
  
  \begin{equation*}
    \begin{aligned}
      A &= [\text{observe an odd number}] = \{1,3,5\} \\
      B &= [\text{observe an even number}] = \{2,4,6\} \\
      C &= [\text{observe a number less than 5}] = \{1,2,3,4\} \\
      D &= [\text{observe a 2 or a 3}] = \{2,3\}\\
      E_1 &= [\text{observe a 1}] = \{1\}
    \end{aligned}
    \qquad
    \begin{aligned}
      E_2 &= [\text{observe a 2}] = \{2\} \\
      E_3 &= [\text{observe a 3}] = \{3\} \\
      E_4 &= [\text{observe a 4}] = \{4\} \\
      E_5 &= [\text{observe a 5}] = \{5\} \\
      E_6 &= [\text{observe a 6}] = \{6\}
    \end{aligned}
  \end{equation*}

  \item Some observations about events:
  \begin{itemize}
    \item The sample points are \textit{elements} of $S$. The simple events are
    \textit{singleton subsets} of $S$. In the dice example, we have:
    \begin{itemize}
      \item Sample points: 1,2,3,4,5,6.
      \item Simple events: $\left\{1\right\},\left\{2\right\},\left\{3\right\},\left\{4\right\},\left\{5\right\},\left\{6\right\}$.
    \end{itemize}
    \item The empty set $\emptyset$ and the whole sample space $S$ are always
    both events: $\emptyset$ is the event ``nothing happens'' and $S$ is the
    event ``something happens''.
    \item Events satisfy the properties of a boolean algebra:
    \begin{itemize}
      \item \textbf{``And'':} If $E$ and $F$ are events, then $E\cap F$ is the
      event that $E$ and $F$ occur.
      \item \textbf{``Or'':} If $E$ and $F$ are events, then $E\cup F$ is the
      event that $E$ or $F$ occurs.
      \item \textbf{``Not'':} If $E$ is an event, then $E^{c}= S\backslash E$
      is the event that $E$ does not occur.
    \end{itemize}
  \end{itemize}
  \item Two events $E$ and $F$ are \demph{mutually exclusive} if
  $E\cap F =\emptyset$. This means that $E$ and $F$ cannot both happen at the
  same time.

  In the dice example, the events $A$ and $B$ are mutually exclusive, since
  the dice roll cannot be both even and odd. But $A$ and $C$ are not mutually
  exclusive because $A\cap C =\left\{1,3\right\}\neq \emptyset$. If a 1 or a 3
  is rolled, then both $A$ and $C$ occur.
\end{itemize}

\subsubsection{Definition of probability measure}
\begin{definition}[Probability measure]
  Let $S$ be a sample space associated with an experiment. A function $\P$ is
  said to be a \demph{probability measure} on $S$ if it satisfies the
  following three axioms:
  \begin{enumerate}[label=\textbf{A.\arabic*}]
    \item (Nonnegativity) \label{item:probability-axiom-nonnegativity} For
    every event $E\subseteq S$,
    \begin{equation*}
      \P\left[E\right] \geq 0.
    \end{equation*}
    \item (Total mass one) $\P\left[S \right] =1$.
    \item (Countable additivity) If $E_{1},E_{2},\ldots$ is a sequence of
    events which are pairwise mutually exclusive (meaning
    $E_{i}\cap E_{j}=\emptyset$ if $i\neq j$), then
    \begin{equation*}
      \P\left[E_{1}\cup E_{2}\cup \ldots \right] = \sum_{i=1}^{\infty} \P\left[E_{i} \right].
    \end{equation*}
  \end{enumerate}
  If $\P$ is a probability measure, then for every event $E\subseteq S$, the
  number $\P\left[E \right]$ is called the \demph{probability} of $E$.
\end{definition}

The above definition only tells us the conditions an assignment of
probabilities must satisfy; it doesn't tell us how to assign specific
propabilities to events.

Probability measures satisfy some basic properties:

\begin{proposition}[Basic properties of probability measure]
  \label{prop:some-deductions-from-axioms}
  If $\P$ is a probability measure, then the following properties hold:
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item (The null event has probability zero) \label{item:empty-set-has-prob-zero}
    $\P\left[\emptyset \right] = 0$.
    \item (Finite additivity) \label{item:finite-additivity} Let $\left\{E_{1},\ldots,E_{n}\right\}$ be a
    \textit{finite} sequence of events. If the sequence is pairwise disjoint, then
    \begin{equation*}
      \P\left[E_{1}\cup E_{2}\cup\ldots\cup E_{n} \right] 
      = \P\left[E_{1} \right]+\P\left[E_{2} \right]+\ldots+\P\left[E_{n} \right].
    \end{equation*}
    \item (``With probability one, an event $E$ either does occur or doesn't'') \label{item:complements} $\P\left[E^{c} \right] = 1-\P\left[E \right]$.
    \item (Excision Property) \label{item:excision-property} If $A,B$ are events and $A\subseteq B$, then
    \begin{equation*}
      \P\left[B\backslash A \right] = \P\left[B \right] - \P\left[A \right].
    \end{equation*}
    \item (``The particular is less likely than the general'') \label{item:subsets} If $A,B$ are events and $A\subseteq B$, then
    $\P\left[ A\right] \leq \P\left[B \right]$.
    \item (``Probabilities are between 0 and 1'') \label{item:probabilities-are-in-unit-interval} For any event $E$,  $\P\left[E \right]\in [0,1]$.
  \end{enumerate}
\end{proposition}

\section{2026-01-14 | Week 01 | Lecture 02}
\begin{center}
  \begin{tcolorbox}[width=0.9\textwidth, colback=white, colframe=black]
    \textit{\textbf{The topic of this lecture:} independent events, conditional
      probabilities, random variables}
  \end{tcolorbox}
\end{center}

\subsection{Independent events and conditional probabilities}
\textit{This section is based on section 2.7 in the textbook.}

\begin{definition}[Independence]
  \label{def:independence}
  Two events $A$ and $B$ are said to be \demph{independent} if $\P\left[A\cap
    B \right] = \P\left[A \right] \P\left[B \right]$. Otherwise, the events
  are said to be dependent.
\end{definition}

\begin{definition}[Conditional probability]
  Let $A,B$ be events, and assume that $\P\left[B\right]>0$. Then the
  \demph{conditional probability of $A$, given $B$}, denoted
  $\P\left[A\mid B \right]$, is given by the formula
  \begin{equation*}
    \P\left[A\mid B \right] = \frac{\P\left[A\cap B \right]}{\P\left[B \right]}.
  \end{equation*}
\end{definition}

\fl{Interpretation:} $\P\left[A\mid B \right]$ is the probability of $A$ when
we know that event $B$ happened.

\begin{definition}
  \label{def:positive-relationship}
  We say that there exists a \demph{positive relationship} between events $A$
  and $B$ if
  \begin{equation*}
    \P\left[A\mid B \right]> \P\left[A \right],
  \end{equation*}
  and a \demph{negative relationship} if
  \begin{equation*}
    \P\left[A\mid B \right]< \P\left[A \right].
  \end{equation*}
\end{definition}

\begin{remark}
  Note the the conditions of \cref{def:positive-relationship} are symmetric in
  the sense that
  \begin{equation*}
    \P\left[A\mid B \right]> \P\left[A \right] \iff \P\left[B\mid A \right]>
    \P\left[B \right],
  \end{equation*}
  provided that both $A$ and $B$ have positive probability.
\end{remark}

\begin{example}
  Roll a 6-sided dice. Let $A$ be the event that a `2' was rolled, and $B$ be
  the event that an even number was observed.

  \begin{itemize}
    \item The unconditional probability: $\P\left[A \right]=1/6$.
    \item The conditional probability: $\P\left[A\mid B \right] = 1/3$.
  \end{itemize}
  Since $\frac{1}{3}>\frac{1}{6}$, we conclude there is a positive
  relationship between rolling a `2' and rolling an even number.
\end{example}

The notion of independence formalizes the idea of ``no relationship''.

\begin{proposition}
  \label{prop:independence-interpretation}
  If $A,B$ are events with positive probabilities then the following are
  equivalent:
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item $A$ and $B$ are independent.
    \item $\P\left[A\mid B \right] = \P\left[A \right]$
    and $\P\left[B\mid A \right] = \P\left[B \right]$.
  \end{enumerate}
\end{proposition}
In words, independence means that the probabilities of each event are
unaffected by whether or not the other event occurs.
\cref{prop:independence-interpretation} simply formalizes this idea using
conditional probabilities.


\subsection{Random variables}
\textit{Based on Sections 2.11, 4.2 in the textbook}


\begin{definition}[Random variable]
  A \demph{random variable} (or \demph{rv}) is a real-valued function whose domain is a sample
  space.
\end{definition}

The value of a random variable is thought of as varying depending on the
outcome of the experiment (the sample point). Random variables are usually
denoted with capital letters, like $X,Y,Z$.

\begin{example}[Sum 2d4]
  \label{ex:sum-2d4}
  Roll a 4-sided dice twice (this is the \textbf{experiment}). There are 16 possible
  \textbf{outcomes}. The \textbf{sample space} is
  \begin{equation*}
    S = \left\{(x,y): x,y\in \left\{1,2,3,4\right\} \right\}.
  \end{equation*}
  Let $X$ be the sum of the two rolls. We can represent $X$ by the following table:
  \begin{equation*}
    \begin{array}{c@{\quad}c|cccc} & \multicolumn{5}{c}{\text{Dice 2}} \\ & &
      1 & 2 & 3 & 4 \\ \cline{2-6}  & 1 & 2 & 3 & 4 & 5 \\ \text{Dice 1} & 2 & 3 & 4 & 5 & 6 \\ & 3 & 4 & 5 & 6 & 7 \\ & 4 & 5 & 6 & 7 & 8 \end{array}
  \end{equation*}
  \textbf{Events} are often defined using preimages of random variables. Most
  interesting take the form $[X\in B]$, where $X$ is a random variable and
  $B\subseteq \R$. For example, the event that $X=6$ is:
  \begin{align*}
    [X=6] 
    &= \left\{\omega\in S: X(\omega) = 6\right\} \\
    &= \left\{(1,5), (2,4), (3,3), (4,2), (5,1)\right\}.
  \end{align*}
  The textbook uses the notation $\left\{X=6\right\}$ instead of
  $\left[ X=6 \right]$.

  Here's another example of an event. Let $E = \left\{2,4,6,8\right\}$. Then
  \begin{align*}
    \left[ X \text{ is even} \right]
    &= \left[ X \in E \right]\\
    &= \left\{\omega\in S: X(\omega) \in E \right\} \\
    &= \left\{(1,1), (1,3), (2,2), (2,4), (3,1), (3,3), (4,2), (4,4) \right\}.
  \end{align*}

  When writing random variables, we usually suppress the arguments, e.g.,
  writing $X$ rather than $X(\omega)$.

  
\end{example}
% \begin{example}
%   Consider an experiment in which we flip a coin twice. The sample space is
%   consists of four sample points:
%   \begin{equation*}
%     E_{1} = HH, \quad E_{2}= HT, \quad E_{3} = TH, \quad E_{4} = TT
%   \end{equation*}
%   Let $Y$ be the number of heads flipped. So $Y$ can take three values: $0,1$
%   and $2$. These are examples of events:
%   \begin{equation*}
%     \left[ Y=0 \right] = \left\{E_{4}\right\},
%     \quad \left[ Y=1 \right] = \left\{E_{2},E_{3}\right\},
%     \quad \text{and} \quad  \left[ Y=2 \right] = \left\{E_{1}\right\}.    
%   \end{equation*}
%   We can compute the probabilities of these:
%   \begin{equation*}
%     \P\left[Y=0 \right] = \P\left[E_{4} \right] = 1/4.
%   \end{equation*}
%   and
%   \begin{equation*}
%     \P\left[Y=1 \right] = \P\left[E_{2} \right]+ \P\left[E_{3} \right] = 1/4+1/4 = 1/2.
%   \end{equation*}
% \end{example}

% \begin{definition}[Support]
%   Let $X$ be a random variable. The \demph{support} of $X$, denoted
%   $\text{supp}(X)$ or $S_{X}$, is the smallest closed set $F\subseteq \R$ such
%   that $\P\left[X\in F \right]=1$.
% \end{definition}
% Informally, the support of a random variable is the set of all possible values
% that it can take. In \cref{ex:sum-2d4},
% $\text{supp}(X)= \left\{2,3,4,5,6,7,8\right\}$.
\newpage

\section{2026-01-16 | Week 01 | Lecture 03}

\subsection{Random variables}
\subsubsection{Discrete vs continuous}
\begin{definition}[Discrete random variable]
  \label{def:discrete-random-variable}
  We say that a random variable $X$ is a \demph{discrete random variable} if
  it can assume only a finite or countably infinite number of distinct values.
\end{definition}


\begin{definition}[Probability mass function, pmf]
  Let $X$ be a discrete random variable. The \demph{probability mass function}
  (or \demph{pmf}) of $X$ is the function
  \begin{equation*}
    p(x) = \P\left[X=x \right],
  \end{equation*}
  defined for every $x\in \R$.
\end{definition}

\begin{example}
  The pmf of $X$ in \cref{ex:sum-2d4} is
  \begin{equation*}
    p(2) = 1/16 \quad p(3) = 2/16, \quad p(4) = 3/16, \quad p(5) = 4/16, \quad p(6) = 3/16, \quad p(7)=2/16, \quad p(8) = 1/16
  \end{equation*}
  and $p(x)=0$ for all other $x\in \R$.
\end{example}


\begin{definition}[Distribution function - section 4.2]
  Let $X$ be any random variable. The \demph{cumulative distribution function}
  (or \demph{cdf}) of $X$ is the function
  \begin{equation*}
    F(x) = \P\left[X \leq x\right],
  \end{equation*}
  defined for all $x\in \R$.
\end{definition}

\begin{remark}
  The domain of a cdf is always $\R$, and it is always a nondecreasing
  function with $F(-\infty)=0$ and $F(+\infty)=1$. The cdf of a discrete
  random variable is always a step function.
\end{remark}

\begin{definition}[Continuous rv]
  \label{def:continuous-rv}
  Let $Y$ be a random variable with distribution function $F$. We say that $Y$
  is a \demph{continuous random variable} if there exists a nonnegative
  function $f$ such that
  \begin{equation}\label{eq:1}
    F(y) = \int_{-\infty}^{y}f(t)dt
  \end{equation}
  for all $y\in \R$. The function $f$ is called the \demph{probability density
    function} (or \demph{pdf}) of $Y$.
\end{definition}


\begin{remark}
  For continuous random variables, the distribution function $F$ is always
  continuous. Moreover, for a continuous random variable $Y$,
  $\P\left[Y=b \right]=0$ for all $b\in \R$.
  % \begin{equation*}
  %   \P\left[Y=b \right] 
  %   = \P\left[Y \leq b\right] - \lim_{a \to b^{-}}\P\left[Y \leq a\right] 
  %   = F(b) - \lim_{a \to b^{-}}F(a) = 0
  % \end{equation*}
  % where the last equality follows from continuity of $F$.
\end{remark}

\begin{theorem}[Theorem 4.3 in textbook]
  If $Y$ is a continuous random variable with pdf $f$, then
  \begin{equation*}
    \P\left[a \leq Y \leq b\right] = \int_{a}^{b}f(t)dt
  \end{equation*}
  for all $-\infty \leq a \leq b\leq +\infty$.
\end{theorem}
% \begin{proof}
%   \begin{equation*}
%     \P\left[a \leq Y \leq b\right] = \P\left[Y=a \right]+ \P\left[a<Y \leq b\right]
%   \end{equation*}
%   The result then follows from the following two computations:
%   \begin{align*}
%     \P\left[Y=a \right] = F(a) - F(a-) = \lim_{\epsilon \to 0} \int_{a-\epsilon}^{a}f(t)dt = 0,
%   \end{align*}
%   and
%   \begin{align*}
%     \P\left[a < Y \leq  b\right]
%     &= F(b) - F(a)\\
%     &= \int_{-\infty}^{b}f(t)dt - \int_{-\infty}^{a}f(t)dt\\ 
%     &= \int_{a}^{b}f(t)dt. 
%   \end{align*}
% \end{proof}

\subsubsection{Expected value}
\begin{definition}[Expectation of a continuous random variable]
  \label{def:expectation-continuous-random-variable}
  If $Y$ is a random variable with pdf $f$, then the \demph{expected value} of
  $Y$, denoted $\E\left[Y \right]$, is the quantity
  \begin{equation*}
    \E\left[ Y\right] = \int_{-\infty}^{\infty} y f(y)dy,
  \end{equation*}
  provided that $\int_{-\infty}^{\infty} |y|f(y)dy<\infty$. 
\end{definition}

\begin{remark}
  $\E\left[Y \right]$ is the long-run average of $Y$, if we were to repeat the
  experiment many times.
\end{remark}

The next theorem is called the \textit{Law of the unconscious statistician (LOTUS)}.


\begin{theorem}[LOTUS - single variable case]
  \label{thm:law-unconscious-statistician}
  Let $g:\R \to \R$ be a function.
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item If $X$ has pmf $p$, then
    \begin{equation*}
      \E\left[g(X) \right]= \sum_{\substack{x\in \R\\ p(x)>0}} g(x)p(x).
    \end{equation*}
    \item If $Y$ has pdf $f$, then
    \begin{equation*}
      \E\left[g(Y) \right] = \int_{-\infty}^{\infty}g(y)f(y)dy.
    \end{equation*}

  \end{enumerate}
\end{theorem}

\begin{remark}
  \label{rmk:need-for-joint-distn}
  Often we wish to compute probabilities of functions of multiple random
  variables, for example:
  \begin{itemize}
    \item What is the probability that
    $\frac{X_{1}+\ldots+X_{n}}{n}\in (0,1)$? Here, the function is
    $g(x_{1},\ldots,x_{n})= \frac{x_{1}+\ldots+x_{n}}{n}$.
    \item What is the probability that $\max(X,Y) \leq 10$? Here the function is
    $g(x,y)=\max(x,y).$
    \item Suppose we roll two dice and take the maximum. What is the expected
    value? In this case, our dice rolls are $X,Y$ and we want to compute
    $\E\left[g(X,Y) \right]$, where $g(x,y) = \max(x,y)$.
  \end{itemize}
  To answer these sorts of questions, we need the notion of a ``joint distribution''.
\end{remark}

\subsubsection{Joint distributions}
\textit{This subsection is based on section 5.4 in the textbook. Everything in
  this section generalizes naturally to $n$ variables, but the results are
  simpler to state for just 2 random variables.}



\begin{definition}[Joint pmf]
  \label{def:joint-pmf}
  Let $X_{1}$ and $X_{2}$ be discrete random variables. The \demph{joint
    probability mass function} for $X_{1}$ and $X_{2}$ is the function
  \begin{equation*}
    p(x_{1},x_{2}) = \P\left[X_{1}=x_{1},X_{2}=x_{2} \right],
  \end{equation*}
  defined for all $x_{1},x_{2}\in \R$.
\end{definition}

\begin{definition}[Joint pdf]
  \label{def:joint-pdf}
  Let $Y_{1}$ and $Y_{2}$ be continuous random variables. We say that $Y_{1}$ and $Y_{2}$
  are \demph{jointly continuous} if there exists a function
  $f:\R^{2} \to \R_{ \geq 0}$ such that 
  \begin{equation*}
    \P\left[Y_{1} \leq y_{1}, Y_{2} \leq  y_{2}\right] =  \int_{-\infty}^{y_{1}}\int_{-\infty}^{y_{2}}    f(t_{1},t_{2}) dt_{2}dt_{1}.
  \end{equation*}
  for all $y_{1},y_{2}\in \R$. The function $f$ is called the \demph{joint probability
  density function} for $Y_{1}$ and $Y_{2}$.
\end{definition}


\begin{theorem}[LOTUS - multivariable case]
  \label{thm:lotus-multivariable-case}
  Let $g:\R^{2}\to \R$.
  \begin{itemize}
    \item   If $X_{1},X_{2}$ have joint pmf $p(x_{1},x_{2})$, then
    \begin{equation*}
      \E\left[g(X_{1},X_{2}) \right] = \sum_{\substack{(x_{1},x_{2})\in \R^{2}:\\ p(x_{1},x_{2})>0}} g(x_{1},x_{2})p(x_{1},x_{2}).
    \end{equation*}
    \item If $Y_{1},Y_{2}$ are jointly continuous random variables with joint
    pdf $f(y_{1},y_{2})$, then
    \begin{equation*}
      \E\left[g(Y_{1},Y_{2}) \right] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(y_{1},y_{2})f(y_{1},y_{2})dy_{1}dy_{2}.  
    \end{equation*}
  \end{itemize}
\end{theorem}

\begin{remark}
  \cref{thm:lotus-multivariable-case} generalizes to $n$ variables. It gives
  us a way to answer questions like the third question posed in
  \cref{rmk:need-for-joint-distn}.
\end{remark}

\newpage
\section{2026-01-21 | Week 02 | Lecture 04}

\begin{center}
  \begin{tcolorbox}[width=0.9\textwidth, colback=white, colframe=black]
    \textit{\textbf{Question for this lecture:} what does it mean for random
      variables to be independent, and what does it buy us?}
  \end{tcolorbox}
\end{center}


\subsection{Independence of random variables}

\subsubsection{Definition and characterization}
The aim of this section is to define what it means for random variables to be
independent.

\begin{definition}
  \label{def:independence-random-variables}
  We say that the random variables $X_{1},X_{2},\ldots,X_{n}$ are
  \demph{independent} if the following holds for all possible values
  $x_{1},\ldots,x_{n}$ in their range:
  \begin{equation*}
    \P\left[X_{1}\leq x_{1},X_{2}\leq x_{2},\ldots,X_{n}\leq x_{n}\right] = \P\left[X_{1}\leq x_{1}\right] \P\left[X_{2}\leq x_{2}\right] \cdots \P\left[X_{n}\leq x_{n}\right].
  \end{equation*}
\end{definition}

\begin{theorem}[Factorization theorem -- Theorem 5.4 in textbook]
  \label{thm:factorization-theorem}
  For discrete/continuous random variables, independence is equivalent to
  factorizability of the joint pmf/pdf. More formally, we have:
  
  \begin{itemize}
    \item \textbf{Discrete case:} Let $X_{1},\ldots,X_{n}$ be discrete random
    variables. Then $X_{1},\ldots,X_{n}$ are independent if and only if
    \begin{equation*}
      \P\left[X_{1}=x_{1},X_{2}=x_{2},\ldots, X_{n}=x_{n} \right] = \P\left[X_{1}= x_{1}\right]\P\left[X_{2}= x_{2}\right]\cdots \P\left[X_{n}= x_{n}\right]
    \end{equation*}
    for all $x_{1},\ldots,x_{n}\in \R$.
    \item \textbf{Continuous case:} Let $Y_{1},\ldots,Y_{n}$ be continuous
    random variables with pdfs $f_{1},\ldots,f_{n}$, and joint pdf
    $f:\R^{n} \to \R$. Then $Y_{1},\ldots,Y_{n}$ are independent if and only if
    \begin{equation*}
      f(y_{1},\ldots,y_{n}) = f_{1}(y_{1}) f_{2}(y_{2})\cdots f_{n}(y_{n})
    \end{equation*}
    for all $y_{1},\ldots,y_{n}\in \R$.
  \end{itemize}
\end{theorem}

\begin{remark}
  In this course, we will frequently work with ``samples'' of $n$ independent
  random variables $X_{1},\ldots,X_{n}$. The intuition about independence for
  $n$ variables is that observing any number of them doesn't give you any
  information about the others.
\end{remark}
% \begin{definition}[Random vector]
%   Let $S$ be a sample space. A function\footnote{measureable} $X:S \to \R^{n}$
%   is called a \demph{random vector}.
% \end{definition}


% In other words, it is a vectors whose entries are random variables
% $X=(X_{1},\ldots,X_{n})$. The distribution of a random vector is simply the
% joint distribution of $X_{1},\ldots,X_{n}$.


\subsubsection{Independence and expectations/variances}

Independence splits the expectation of a product into a product of expectations.
\begin{theorem}
  \label{thm:independence-splits-expectations}
  If $X_{1},X_{2},\ldots X_{n},$ are independent, then
  \begin{equation*}
    \E\left[X_{1}X_{2}\cdots X_{n} \right] = \E\left[X_{1} \right] \E\left[X_{2} \right] \cdots \E\left[X_{n} \right],
  \end{equation*}
  provided that the expectations exist.
\end{theorem}
\begin{proof}
  This can be proven for continuous/discrete random variables by an
  application of \cref{thm:lotus-multivariable-case}.
\end{proof}


\begin{definition}[Variance of a random variable]
  \label{def:variance-random-variable}
  Let $X$ be a random variable. The \demph{variance} of $X$, denoted
  $\Var(X)$, is the quantity
  \begin{equation*}
    \Var(X) = \E\left[(X-\mu)^{2} \right].
  \end{equation*}
  where $\mu= \E\left[X \right]$. The positive square root of the variance is
  the \demph{standard deviation} of $X$.
\end{definition}

\begin{remark}
  Variance often denoted by $\sigma^{2}$. The textbook uses the notation
  $V(X)$ instead of $\Var(X)$.
\end{remark}


\begin{theorem}
  \label{thm:variance-properties}
  Let $X$ be a random variable and $a,b$ be scalars. Then
  \begin{equation*}
    \Var(aX+b) = a^{2}\Var(X).
  \end{equation*}
  If $X$ and $Y$ are independent random variables then
 \begin{equation*}
    \Var(X+Y) = \Var(X)+\Var(Y).
  \end{equation*}
\end{theorem}
\begin{proof}
  Follows by direct computation using the definition of variance.
\end{proof}

The second part of \cref{thm:variance-properties} says that for independent
random variables, variance is additive.

\subsubsection{Independence and long-term behavior: the weak law of large numbers}

Combining many independent sources of randomness tends to produce predictible
phenmonena. Here we introduce one example of that. 

We will need the following theorem, which says that if the average male height
is 5 feet tall, then no more than 10\% of men can be more than 50 feet tall.

\begin{theorem}[Markov's inequality]
  \label{thm:markovs-inequality}
  Let $X$ be a nonnegative random variable and let $a>0$. Then
  \begin{equation}\label{eq:2}
    \P\left[X \geq a\right] \leq \frac{\E\left[X \right]}{a}
  \end{equation}
\end{theorem}
\begin{proof}
  Let $E= \left[ X \geq a\right]$. Then $X \cdot \mathbf{1}_{E}\leq X$, so
  \begin{align*}
    \E\left[X \right] 
    &\geq \E\left[X \cdot \mathbf{1}_{E} \right]\\
    &\geq \E\left[a \mathbf{1}_{E}\right]\\
    &\geq a \E\left[\mathbf{1}_{E} \right]\\
    &=a \P\left[E \right]\\
    &=a \P\left[X \geq a\right].
  \end{align*}
  Dividing by $a$ implies \cref{eq:2}.
\end{proof}
\begin{theorem}[Weak Law of Large Numbers]
  \label{thm:weak-law-large-numbers}
  Let $(X_{n})_{n=1}^{\infty}$ be a sequence of independent random variables.
  Assume that for all $n$, $\mu= \E\left[X_{n} \right]$ and
  $\Var(X_{n}) \leq B$ for some fixed bound $B<\infty$. Let
  $S_{n}=X_{1}+\ldots+X_{n}$. Then for all $\epsilon>0$,
  \begin{equation*}
    \P\left[ \left| \frac{S_{n}}{n}-\mu \right| >\epsilon\right] \to 0 \text{
      as } n \to \infty.
  \end{equation*}
\end{theorem}
\begin{proof}
  First observe that by independence,
  \begin{equation}\label{eq:3}
    \Var(S_{n}) = \Var(X_{1})+\ldots+\Var(X_{n}) \leq nB.
  \end{equation}
  Next, let $\epsilon>0$ be arbitrary.
  \begin{align*}
    \P\left[\left| \frac{S_{n}}{n}-\mu \right| >\epsilon\right]
    &= \P\left[\left| S_{n}-n\mu \right|> n\epsilon \right]\\
    &= \P\left[ \left( S_{n}-n\mu \right)^{2} > (n\epsilon)^{2}  \right]\\
    &\leq  \frac{\E\left[\left( S_{n}-n\mu \right)^{2}
      \right]}{n^{2}\epsilon^{2}} &&\text{by \cref{thm:markovs-inequality}}\\
    &= \frac{\Var(S_{n})}{n^{2}\epsilon^{2}} &&\text{by definition of variance }\\
    &\leq \frac{B}{\epsilon^{2}n} &&\text{by \cref{eq:3}}.
  \end{align*}
  The right hand side tends to zero as $n \to \infty$, proving the theorem.
\end{proof}

\subsection{Equality in distribution}
\begin{definition}[Identically distributed]
  \label{def:identically-distributed}
  Two random variables $X$ and $Y$ are \demph{identically distributed} if they
  have the same cdf.
\end{definition}
\begin{remark}
  Identically distributed random variables are said to ``have the same
  distribution''. For discrete/continuous random variables, this is equivalent
  to them having the same pmf/pdf.
\end{remark}

The next example shows that identically distributed random variables need not
be equal as functions.

\begin{example}
  Flip a coin. Define two random variables
  \begin{equation*}
    X = \left\{ \begin{array}{l@{\quad:\quad}l} 1 &\text{coin is heads} \\ 0&
        \text{coin is tails} \end{array}\right.
  \end{equation*}
  \begin{equation*}
    Y = \left\{ \begin{array}{l@{\quad:\quad}l} 0 &\text{coin is heads} \\ 1&
        \text{coin is tails} \end{array}\right.
  \end{equation*}
  Then $X$ and $Y$ are identically distributed, since they have the same pmf:
  \begin{equation*}
    \P\left[X=1 \right] = \P\left[Y=1 \right]=\frac{1}{2}
    \quad \text{and} \quad
    \P\left[X=0 \right] = \P\left[Y=0 \right]=\frac{1}{2}.
  \end{equation*}
  But of course $X$ and $Y$ are never equal, i.e., $\P\left[X\neq Y \right]=1$.
\end{example}

% \begin{theorem}[Law of Large Numbers]
%   \label{thm:law-large-numbers}
%   Let $X_{1},X_{2},\ldots$ be a sequence of independent random variables with
%   finite variance and common mean $\mu$. Then
%   \begin{equation*}
%     \frac{X_{1}+\ldots+X_{n}}{n} \to \mu
%   \end{equation*}
% \end{theorem}

% \begin{theorem}[Central Limit Theorem]
%   \label{thm:central-limit-theorem}
%   Let $X_{1},\ldots,X_{n}$ be independent identically distributed random
%   variables with $\E\left[X_{i} \right]=\mu$ and $\Var(X_{i}) =
%   \sigma^{2}<\infty$. Let
%   \begin{equation*}
%     U_{n} = \frac{\overline{X}-\mu}{\sigma \sqrt{n}}  \to \mathcal{N}(0,1)
%   \end{equation*}
% \end{theorem}


\subsection{Populations and samples}

\textit{For discussions of ``random sample'', see sections 2.12 and 6.1 in the textbook.}

Here we introduce a conceptual framework for mathematical statistics.

A \demph{population} is a large body of data that is the target of our
interest. The subset collected from it is our \demph{sample}. 

\begin{example}[Populations]
  A population can be real or theoretical. Here are some examples
  \begin{itemize}
    \item The set of people in Hawaii (real, finite)
    \item The set of voters in the 2026 Midterm elections (hypothetical, finite)
    \item The decimal expansion of $\pi$ (countably infinite)
    \item The infinitely many observations that could be made during a
    laboratory experiment if the experiment were repeated over and over again
    (hypothetical)
    \item The lifetimes of light bulbs produced by a factory
  \end{itemize}
  Importantly, a population can also be a \textit{probability distribution},
  specified by a pdf, pmf, or cdf
  \begin{itemize}
    \item Observations made from an exponential distribution with mean
    $\lambda>0$ (i.e., the distribution with pdf
    $f(x)=\lambda e^{-\lambda x}\mathbf{1}_{\left[ x>0 \right] }$.)
  \end{itemize}
\end{example}


The simpleset sampling procedure is called simple random sampling.

\begin{definition}[Simple random sampling]
  Let $N$ and $n$ denote the numbers of elements in the population and sample,
  respectively. If the sampling is conducted in such a way that each of the
  ${N\choose n}$ samples has an equal probability of being selected, the
  sampling is called \demph{simple random sampling}, and the result is a
  \demph{simple random sample}.
\end{definition}

More commonly in mathematical statistics, we think of the population as a
distribution.

\begin{definition}[Random sample from a distribution]
  Consider a given probability distribution on $\R$ that can be represented by
  a pdf or pmf $f$. We say that the random variables $X_{1},\ldots,X_{n}$ form
  a \demph{random sample} from this distribution if these random variables are
  independent and the distribution of each is given by $f$. Such random
  variables are also said to be \demph{independent and identically
    distributed} (iid). The number of random variables $n$ is the
  \demph{sample size}.
\end{definition}


\textit{The objective of statistics to is to make an inference about a
  population based on information contained in a sample from that population
  and to provide an associated measure of goodness for the inference.}


\subsection{What is a statistic?}
\textit{Section 7.1 in the textbook.}

\begin{definition}[Statistic]
  A \demph{statistic} is a function of the observable random variables in a
  sample and known constants.
\end{definition}

In other words, if $X_{1},\ldots,X_{n}$ is a random sample and
$T:\R^{n}\to \R$ is a function, then the random
variable
\begin{equation*}
  Y = T(X_{1},\ldots,X_{n})
\end{equation*}
is a statistic.\footnote{A statistic does not need to be real-valued, but we
  will focus on the case when it is.} The probability distribution of such a
statistic $Y$ is called its \demph{sampling distribution}.

Often, we have some quantity of interest, called a \demph{target parameter},
and we want a single ``best guess'' of some quantity of interest. When this is
the case, the we call a statistic an estimator:

\begin{definition}[Estimator]
  \label{def:estimator}
  An \demph{estimator} is a statistic, that is a function
  $T(X_{1},\ldots,X_{n})$ of a sample, that is used to approximate a target
  parameter.
  An \demph{estimate} is the realized value of an
  estimator (e.g., a number) that is obtained when the sample is actually
  taken.
\end{definition}
In words, an estimator is a rule, often expressed as a formula, that tells us
how to calculate the value of an estimate based on the measurements contained
in a sample. Here are two important examples of estimators.

\begin{definition}[Sample Mean, Sample Variance]
  Let $X_{1},\ldots,X_{n}$ be a random sample. The \demph{sample mean},
  denoted $\overline{X}$, is the statistic
  \begin{equation*}
    \overline{X} = \frac{1}{n}\sum_{i=1}^{n}X_{i}.
  \end{equation*}
  The \demph{sample variance}, denoted $S^{2}$, is the statistic
  \begin{equation*}
    S^{2} = \frac{1}{n-1} \sum_{i=1}^{n} (X_{i}-\overline{X})^{2}.
  \end{equation*}
\end{definition}

The target parameters these are used to estimate are the mean and variance of
the population.


The following examples illustrates some of the terminology we've introduced.

\begin{example}
  Suppose the lifetime of each light bulb produced in a certain factory is
  distributed according to the following pdf
  \begin{equation*}
    f(y)= \lambda e^{-\lambda y}\mathbf{1}_{\left[ y>0 \right] }.
  \end{equation*}
  for some parameter $\lambda>0$, where $y$ is measured in minutes. Here, the
  \textbf{population} is the distribution of lifetimes. Suppose we do not know
  $\lambda$, and we wish to estimate it. Hence $\lambda$ is the \textbf{target
    parameter}.
  
  A random sample $Y_{1},\ldots,Y_{n}$ is taken. (So the $Y_{i}$'s are
  independent and each as pdf $f$.)

  \begin{claim}
    The \textbf{joint pdf} of $Y_{1},\ldots,Y_{n}$ is the function
    \begin{equation*}
      g(y_{1},\ldots,y_{n}) = \lambda^{n} e^{-\lambda(y_{1}+\ldots+y_{n})} \mathbf{1}_{\left[ \min(y_{1},\ldots,y_{n})>0 \right]},
    \end{equation*}
    defined for all $y_{1},\ldots,y_{n}\in \R$
  \end{claim}
  \begin{claimproof}
    Using the fact that $Y_{1},\ldots,Y_{n}$ in independent continuous random variables,
    \begin{align*}
      g(y_{1},\ldots,y_{n}) 
      &= f(y_{1})\cdots f(y_{n}) &&\text{by \cref{thm:factorization-theorem}}\\
      &= \prod_{i=1}^{n}\left(\lambda e^{-\lambda y_{i}}\mathbf{1}_{\left[ y_{i}>0 \right] }\right)\\ 
      &= \lambda^{n} e^{-\lambda(y_{1}+\ldots+y_{n})} \left( \prod_{i=1}^{n}\mathbf{1}_{\left[ y_{i}>0 \right] }  \right)\\ 
      &= \lambda^{n} e^{-\lambda(y_{1}+\ldots+y_{n})} \mathbf{1}_{\left[ \min(y_{1},\ldots,y_{n})>0 \right]}.
    \end{align*}
  \end{claimproof}
  
  \begin{claim}
    If $Y$ has pdf $f$, then $\E\left[Y \right]= \frac{1}{\lambda}$.
  \end{claim}
  \begin{claimproof}
    \begin{align*}
      \E\left[Y \right]
      &= \int_{-\infty}^{\infty} y\lambda e^{-\lambda y} \mathbf{1}_{\left[ y>0 \right] }dy\\
      &= \int_{0}^{\infty} y\lambda e^{-\lambda y}dy\\ 
      &=\int_{0}^{\infty}e^{-\lambda y}dy &&\text{by integration by parts}\\ 
      &= \frac{1}{\lambda}.
    \end{align*}
  \end{claimproof}
  By \cref{thm:weak-law-large-numbers} (The Weak Law of Large Numbers), the \textbf{statistic}
  \begin{equation*}
    \overline{Y}= \frac{Y_{1}+\ldots+Y_{n}}{n}
  \end{equation*}
  is likely to be close to $\E\left[Y \right] = 1/\lambda$ when $n$ is large.
  Therefore a reasonable \textbf{estimator} for $\lambda$ is
  \begin{equation*}
    \frac{1}{\overline{Y}} = \frac{n}{Y_{1}+\ldots+Y_{n}}.
  \end{equation*}
  If $n=10$ and the observed values of $Y_{1},\ldots,Y_{10}$ are
  \begin{equation*}
    2,~ 0.8,~ 0.1,~ 2.3,~ 3.2,~ 5.4,~ 2,~ 0.4,~ 2.8,~ \text{ and }3.4
  \end{equation*}
  then $\overline{Y}=2.24$, and hence our \textbf{estimate} for $\lambda$ would be
  $\frac{1}{2.24}\approx 0.45$.
\end{example}


\begin{example}[Example 7.1 in textbook]
  Roll a dice three times. Let $Y_{1},Y_{2},Y_{3}$ be the values of the rolls.
  The average number observed in this sample of size 3 is
  \begin{equation*}
    \overline{Y} = \frac{Y_{1}+Y_{2}+Y_{3}}{3}.
  \end{equation*}
  This is the \textbf{sample mean}, and is the first example of a \textbf{statistic}
  that we'll see. What the mean $\mu_{\overline{Y}}$ and standard deviation
  $\sigma_{\overline{Y}}$ of the random variable $\overline{Y}$?

  First we compute the mean and variance of a single $Y_{i}$.
  \setcounter{claimcount}{0}
  \begin{claim}
    \label{claim:mean-and-variance-of-dice}
    $\E\left[Y_{i} \right]=3.5$ and $\Var(Y_{i}) = 35/12 \approx 2.9167$. 
  \end{claim}
  \begin{claimproof}
    Using the definition of expected value,
    \begin{equation*}
      \E\left[Y_{i} \right] = \sum_{k=1}^{6}k \P\left[Y_{i}=k \right]=
      \sum_{k=1}^{6}k \frac{1}{6}=3.5.
    \end{equation*}

    Next we compute the variance of $Y_{i}$:
    \begin{align*}
      \Var(Y_{i}) 
      &= \E\left[\left( Y_{i}-3.5 \right)^{2}  \right] &&\text{\cref{def:variance-random-variable} }\\
      &= \sum_{k=1}^{6}(k-3.5)^{2} \P\left[Y_{i}=k \right] &&\text{By \cref{thm:law-unconscious-statistician} (LOTUS) using
                                                              $g(x)=(x-3.5)^{2}$ }\\
      &= \sum_{k=1}^{6}(k-3.5)^{2} \frac{1}{6} &&\text{since $\P\left[Y_{i}=k
                                                  \right]=1/6$ for all $k\in [6]$ }\\
      &= 35/12.
    \end{align*}
  \end{claimproof}

  
  \begin{claim}
    $\E\left[\overline{Y} \right] = 3.5$
  \end{claim}
  \begin{claimproof}
    We have:
    \begin{align*}
      \E\left[\overline{Y} \right] 
      &= \E\left[\frac{Y_{1}+Y_{2}+Y_{3}}{3} \right] &&\text{by definition of $\overline{Y}$}\\
      &= \frac{1}{3} \left( \E\left[Y_{1} \right]+\E\left[Y_{2}
        \right]+\E\left[Y_{3} \right] \right) &&\text{by linearity of expectation}\\ 
      &= \frac{1}{3} \left( 3.5+3.5+3.5 \right) &&\text{by \cref{claim:mean-and-variance-of-dice}}\\ 
      &= 3.5.
    \end{align*}
  \end{claimproof}


  \begin{claim}
    \label{claim:variance-of-average-of-3-dice-rolls}
    $\Var(\overline{Y})= .9722$
  \end{claim}
  \begin{claimproof}
    \begin{align*}
      \Var(\overline{Y})
      &= \Var \left(  \frac{Y_{1}+Y_{2}+Y_{3}}{3} \right)\\ 
      &= \frac{1}{9}\Var \left( Y_{1}+Y_{2}+Y_{3} \right) &&\text{by \cref{thm:variance-properties} }\\ 
      &= \frac{1}{9}\left( \Var(Y_{1})+\Var(Y_{2})+\Var(Y_{3}) \right)
      &&\text{by \cref{thm:variance-properties}}\\
      &= \frac{1}{9} \left(2.9167+2.9167+2.9167 \right) &&\text{by \cref{claim:mean-and-variance-of-dice}}\\
      &= \frac{2.9167}{3} &&(*) \\
      &= .9722
    \end{align*}
  \end{claimproof}

  Since the standard deviation is the square root of the variance, the
  standard deviation is $\sqrt{.9722}= .9860$ by
  \cref{claim:variance-of-average-of-3-dice-rolls}.

  \begin{remark}
    In equation $(*)$, we had $\Var(\overline{Y}) = \frac{2.9167}{3}$. Notice
    how, if we computed the variance of four or five dice rolls, we'd get
    \begin{equation*}
      \Var(\overline{Y})=\frac{2.9167}{4} \quad \text{or} \quad \Var(\overline{Y})=\frac{2.9167}{5}.
    \end{equation*}
    In general, for $n$ dice rolls, we'd get
    \begin{equation*}
      \Var(\overline{Y}) = \frac{2.9167}{n}.
    \end{equation*}
    This quantity tends to zero as $n \to \infty$. The variance of a sample
    mean decreases as $n$ grows.
  \end{remark}
\end{example}


\textit{Begin section 7.2}

\begin{definition}
  A random variable $Y$ is said to be \demph{normally distributed} with mean
  $\mu\in \R$ and variance $\sigma^{2}>0$ if it has pdf
  \begin{equation*}
    f(y) = \frac{1}{\sqrt{2\pi\sigma^{2}}} \exp\left\{-\frac{(y-\mu)^{2}}{2\sigma^{2}} \right\},
  \end{equation*}
  defined for all $y\in \R$. We abbreviate this by writing
  $Y\sim \mathcal{N}(\mu,\sigma^{2})$. If $Y\sim \mathcal{N}(0,1)$, we say $Y$
  has \demph{standard normal distribution}.
\end{definition}


\begin{theorem}
  \label{thm:normal-sample-means}
  Let $Y_{1},\ldots,Y_{n}$ be a random sample of size $n$ from a normal
  distribution with mean $\mu$ and variance $\sigma^{2}$. Then
  \begin{equation*}
    \overline{Y}= \frac{1}{n} \sum_{i=1}^{n}Y_{i} 
  \end{equation*}
  is normally distributed with mean $\mu_{\overline{Y}}=\mu$ and variance
  $\sigma^{2}_{\overline{Y}}=\sigma^{2}/n$.
\end{theorem}
\begin{proof}[Proof sketch]
  The proof follows from three facts:
  \begin{itemize}
    \item Any linear combination of normal random variables is a normal random
    variable (this can be proved using moment generating functions).
    \item That $\E\left[\overline{Y} \right]=\mu$ follows by linearity of
    expectation.
    \item The variance calculation follows by \cref{thm:variance-properties}.
  \end{itemize}
\end{proof}

\begin{remark}
  \label{rmk:sample-mean-standardized}
  The random variable $Z =
  \frac{\overline{Y}-\mu_{\overline{Y}}}{\sigma_{\overline{Y}}} = 
   \frac{\overline{Y}-\mu}{\sigma/\sqrt{n}} $
  has a standard normal distribution.
\end{remark}



\begin{example}[Example 7.2 in textbook]
  A bottling machine discharages an average of $\mu$ ounces per bottle. It
  has been observed that the amount of liquid discharged is normally
  distributed with standard deviation $\sigma=1$ per ounce.

  A sample of $n=9$ filled bottles is randomly selected, and is measured.

  Find the probability that the sample mean will be within $.3$ ounces of the
  true mean $\mu$.


  \Fl{Solution:} Let $Y_{1},\ldots,Y_{9}$ be the ounces in each of the
  bottles. Then $Y_{i}\sim \mathcal{N}(\mu,1)$ for $i\in [9]$. By
  \cref{thm:normal-sample-means}, $\overline{Y}\sim \mathcal{N}(\mu,
  \sigma^{2}/n)$, and $\sigma^{2}/n=1/9$. We want to find
  \begin{align}\label{eq:4}
    \P\left[\left| \overline{Y}-\mu \right| \leq .3\right] 
    &= \P\left[-.3 \leq \overline{Y}-\mu \leq .3\right] \nonumber\\
    &= \P\left[- \frac{.3}{\sigma/\sqrt{n}}\leq \frac{\overline{Y}-\mu}{\sigma/\sqrt{n}} \leq \frac{.3}{\sigma/\sqrt{n}}\right].
  \end{align}
  By \cref{rmk:sample-mean-standardized},
  $Z=\frac{\overline{Y}-\mu}{\sigma/\sqrt{n}}\sim \mathcal{N}(0,1)$, and
  plugging in $\sigma=1$ and $n=9$ and simplifying gives
  \begin{align*}
    \P\left[\left| \overline{Y}-\mu \right| \leq .3\right] 
    &= \P\left[-.9 \leq Z \leq .9\right]\\
    &= 1- 2 \P\left[Z>.9 \right]\\
    &=.6318.
  \end{align*}
\end{example}

\begin{example}[Example 7.3 in textbook]
  How many observations need to be included in the sample to ensure that
  $\overline{Y}$ is within $.3$ ounces of $\mu$ with probability $.95$?

  Now we want
  \begin{equation*}
    \P\left[\left| \overline{Y} -\mu \right| \leq .3\right] = .95.
  \end{equation*}
  By \cref{eq:4}, 
  \begin{equation*}
    \P\left[\left| \overline{Y} -\mu \right| \leq .3\right] = \P\left[- \frac{.3}{\sigma/\sqrt{n}}\leq \frac{\overline{Y}-\mu}{\sigma/\sqrt{n}} \leq \frac{.3}{\sigma/\sqrt{n}}\right].
  \end{equation*}
  Recalling that $\sigma=1$ and
  $Z=\frac{\overline{Y}-\mu}{\sigma/\sqrt{n}}\sim \mathcal{N}(0,1)$, we have
  \begin{equation*}
    \P\left[\left| \overline{Y}-\mu \right| \leq .3 \right] = \P\left[.3 \sqrt{n}\leq Z \leq .3 \sqrt{n}\right].
  \end{equation*}
  So we need to find $n$ such that $\P\left[.3 \sqrt{n}\leq Z \leq .3
    \sqrt{n}\right]=.95$.

  It is a well-known fact that
  \begin{equation*}
    \P\left[-1.96 \leq Z \leq 1.96\right] = .95.
  \end{equation*}
  So we need $.3 \sqrt{n}=1.96$, or equivalently, $n= \left( \frac{1.96}{.3}
  \right)^{2}= 42.68$.

  So we need at least $43$ samples, since $42$ is not quite enough.
\end{example}

\subsection{Chi-squired distributions}

Define chi-squared distribution, state theorem 7.2.


\end{document}