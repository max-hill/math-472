\documentclass[10pt]{article}
% Math Packages
\usepackage{float} % Required to use [H]
\usepackage{amsmath, mathtools}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{breqn}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}
\usepackage{forest}
\usepackage{tikz-qtree}
\graphicspath{ {./images/} }
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\usepackage[shortlabels]{enumitem}
\usetikzlibrary{arrows,matrix,positioning}
\usepackage{multicol}

\usepackage{mathtools}% http://ctan.org/pkg/mathtools
\usepackage{abraces} %xyz



\usepackage{empheq} % for boxed equations
\usepackage[most]{tcolorbox}
\newtcbox{\mymath}[1][]{%
  nobeforeafter, math upper, tcbox raise base,
  enhanced, colframe=blue!30!black,
  colback=blue!30, boxrule=1pt,
  #1}
\newtcbox{\boxmath}[1][]{%
  nobeforeafter, math upper, tcbox raise base,
  enhanced, colframe=blue!30!black,
  boxrule=1pt,
  #1}

% for the pipe symbol
\usepackage[T1]{fontenc}


% Citing theorems by name. (source: https://tex.stackexchange.com/questions/109843/cleveref-and-named-theorems)
\makeatletter
\newcommand{\ncref}[1]{\cref{#1}\mynameref{#1}{\csname r@#1\endcsname}}

\def\mynameref#1#2{%
  \begingroup
  \edef\@mytxt{#2}%
  \edef\@mytst{\expandafter\@thirdoffive\@mytxt}%
  \ifx\@mytst\empty\else
  \space(\nameref{#1})\fi
  \endgroup
}
\makeatother

% Colorful Notes
\usepackage{color} \definecolor{Red}{rgb}{1,0,0} \definecolor{Blue}{rgb}{0,0,1}
\definecolor{Purple}{rgb}{.5,0,.5} \def\red{\color{Red}} \def\blue{\color{Blue}}
\def\gray{\color{gray}} \def\purple{\color{Purple}}
\newcommand{\rnote}[1]{{\red [#1]}} % \rnote{foo} gives '[foo]' in red
\newcommand{\pnote}[1]{{\purple [#1]}} % \pnote{foo} gives '[foo]' in purple
\newcommand{\bnote}[1]{{\blue #1}} % \bnote{foo} gives 'foo' in blue
\newcommand{\gnote}[1]{{\gray #1}} % \gnote{foo} gives 'foo' in gray
\newcommand{\Max}[1]{{\purple [#1]}} % \bnote{foo} then 'foo' is blue


% Claim numbering (the counter restarts after each proof environment)
\newcounter{claimcount}
\setcounter{claimcount}{0}
\newenvironment{claim}{\refstepcounter{claimcount}\par\addvspace{\medskipamount}\noindent\textbf{Claim \arabic{claimcount}:}}{}
\usepackage{etoolbox}
\AtBeginEnvironment{proof}{\setcounter{claimcount}{0}}
\newenvironment{claimproof}{\par\addvspace{\medskipamount}\noindent\textit{Proof of Claim  \arabic{claimcount}.}}{\hfill\ensuremath{\qedsymbol} \tiny{Claim}

  \medskip}
% Add claim support to cleverref
\crefname{claimcount}{Claim}{Claims}


% Math Environments
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{question}[theorem]{Question}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}


\usepackage{skull}

% Redefine the Example environment to include "End of example [number]"
\makeatletter
\let\oldexample\example
\renewenvironment{example}
{\begin{oldexample}}
  {\par\smallskip\hfill   End of Example~\theexample. $\square$    \par\end{oldexample}}
\makeatother


% Matrices and Column Vectors. 
\usepackage{stackengine}
\setstackgap{L}{1.0\normalbaselineskip}
\usepackage{tabstackengine}
\setstackEOL{;}% row separator
\setstackTAB{,}% column separator
\setstacktabbedgap{1ex}% inter-column gap
\setstackgap{L}{1.5\normalbaselineskip}% inter-row baselineskip
\let\nmatrix\bracketMatrixstack  %Usage: \nmatrix{1,2,3\4,5,6}
\newcommand\cv[1]{\setstackEOL{,}\bracketMatrixstack{#1}} %usage: \cv{1,2,3}

% Custom Math Coqmmands
\newcommand{\vt}{\vskip 5mm} % vertical space
\newcommand{\fl}{\noindent\textbf} % first line
\newcommand{\Fl}{\vt\noindent\textbf} % first line with space above
\newcommand{\norm}[1]{\left\lVert#1\right\rVert} % norm
\newcommand{\pnorm}[1]{\left\lVert#1\right\rVert_p} % p-norm
\newcommand{\qnorm}[1]{\left\lVert#1\right\rVert_q} % q-norm
\newcommand{\1}[1]{\textbf{1}_{\left[#1\right]}} % indicator function 
\def\limn{\lim_{n\to\infty}} % shortcut for lim as n-> infinity
\def\sumn{\sum_{n=1}^{\infty}} % shortcut for sum from n=1 to infinity
\def\sumkn{\sum_{k=1}^{n}} % shortcut for sum from k=1 to n
\def\sumin{\sum_{i=1}^{n}} % shortcut for sum from i=1 to n
\def\SAs{\sigma\text{-algebras}} % shortcut for $\sigma$-algebras
\def\SA{\sigma\text{-algebra}} % shortcut for $\sigma$-algebra
\def\Ft{\mathcal{F}_t} % time-indexed sigma-algebra (t)
\def\Fs{\mathcal{F}_s} % time-indexed sigma-algebra (s)
\def\F{\mathcal{F}} % sigma-algebra
\def\G{\mathcal{G}} % sigma-algebra
\def\R{\mathbb{R}} % Real numbers
\def\N{\mathbb{N}} % Natural numbers
\def\Z{\mathbb{Z}} % Integers
\def\E{\mathbb{E}} % Expectation
\def\P{\mathbb{P}} % Probability
\def\Q{\mathbb{Q}} % Q probability
\def\dist{\text{dist}} %Text 'dist' for things like 'dist(x,y)'
\newcommand{\indep}{\perp \!\!\! \perp}  %independence symbol
\def\Var{\mathrm{Var}} % Variance
\def\tr{\mathrm{tr}} % trace

% Brackets and Parentheses
\def\[{\left [}
    \def\]{\right ]}
% \def\({\left (}
%   \def\){\right )}




\usepackage{color}
\definecolor{Red}{rgb}{1,0,0}
\definecolor{Blue}{rgb}{0,0,1}
\definecolor{Purple}{rgb}{.5,0,.5}
\def\red{\color{Red}}
\def\blue{\color{Blue}}
\def\gray{\color{gray}}
\def\purple{\color{Purple}}
\definecolor{RoyalBlue}{cmyk}{1, 0.50, 0, 0}
\newcommand{\dempfcolor}[1]{{\color{RoyalBlue}#1}} 
\newcommand{\demph}[1]{\textcolor{RoyalBlue}{\textbf{\slshape #1}}} % Slanted
% RoyalBlue text

% comment exactly one of the following line to show / hide the solutions
% \newcommand{\solution}[1]{{\purple #1}} % uncomment to show the solutions
\newcommand{\solution}[1]{} % uncomment to hide the solutions



\title{Lecture Notes for Math 372: \\Elementary Probability and Statistics}
\date{Last updated: \today}
% \author{mh}

\begin{document}
\maketitle




\tableofcontents
\newpage
\setcounter{section}{-1}
\section{Tentative course outline}

This course is a problem-oriented introduction to the basic concepts of probability and statistics,
providing a foundation for applications and further study.
\begin{enumerate}
  \item \textbf{Weeks 1-2.} Sampling distributions (4 lessons).

  chi-squared, t, and F distributions, distributions of sample mean and
  variance

  \item \textbf{Weeks 3-4.} Point estimation (5 lessons)

  properties and methods of point estimation

  \item \textbf{Weeks 5-6.} Interval estimation (4 lessons)

  Confidence intervals for means, variances, proportions and differences

  \item \textbf{Weeks 7-12.} Hypothesis Testing (19 lessons)

  Neyman-Pearson lemma, likelihood ratio test; tests concerning means and
  variances, tests based on count data, nonparametric tests, analysis of variance

  \item \textbf{Weeks 13-14.} Regression and correlation (6 lessons)

  regression, bivariate normal distributions, method of least squares
\end{enumerate}



\newpage
\section{2025-01-12 | Week 01 |  Lecture 01}

\begin{itemize}
  \item give syllabus
  \item do activity with why you're in this course
\end{itemize}


\begin{center}
  \begin{tcolorbox}[width=0.9\textwidth, colback=white, colframe=black]
    \textit{\textbf{The nexus question of this lecture:} What is a
      probability?}
  \end{tcolorbox}
\end{center}
\textbf{Reading assignment:} Sections 1.1, 1.2, 1.3, 2.1, 2.4 of the textbook.

\subsection{What is probability?}
\subsubsection{A general framework: sample space, events, etc}
We begin with a general framework and some terminology to formalize the
notions of probability. This is based on section 2.4 in the textbook.

\begin{itemize}
  \item An \demph{experiment} is an activity or process whose outcome is
  subject to uncertainty, and about which an observation is made.

  Examples include flipping a coin, rolling a dice, measuring the size of a
  wave, or the amount of rainfall, conducting a poll, performing a diagnostic
  test, opening a pack of Pokemon cards, etc.

  \item The \demph{sample space} $S$ of an experiment is the set of all
  possible outcomes. The elements of the sample space are called \demph{sample
    points}.

  We think of each sample point as representing a unique outcome of the
  experiment. In the case of rolling a dice, the sample points are $1,2,3,4,5$
  and $6$, and the sample space is $S=\left\{1,2,3,4,5,6\right\}$.


  \item We use the term \demph{event} to refer to a collection of
  outcomes, i.e., a subset of $S$.

  Example: if our experiment is rolling a 6-sided dice, here are some events

  \begin{equation*}
    \begin{aligned}
      A &= [\text{observe an odd number}]\\
      B &= [\text{observe an even number}]\\
      C &= [\text{observe a number less than 5}]\\
      D &= [\text{observe a 2 or a 3}]\\
      E_1 &= [\text{observe a 1}]
    \end{aligned}
    \qquad
    \begin{aligned}
      E_2 &= [\text{observe a 2}]\\
      E_3 &= [\text{observe a 3}]\\
      E_4 &= [\text{observe a 4}]\\
      E_5 &= [\text{observe a 5}]\\
      E_6 &= [\text{observe a 6}]
    \end{aligned}
  \end{equation*}

  \item There are two types of events: \demph{compound events}, which can be
  decomposed into other events, and \demph{simple events}, which cannot.

  In the above example, the events $A,B,C$ and $D$ are compound events. $E_{1},\ldots,E_{6}$ are simple events.

  \item A sample space is \demph{discrete} if it is countable (i.e., finite or
  countably infinite). In a discrete sample space $S$, the set of all possible
  events is the \textit{power set} of $S$.\footnote{If $S$ is not discrete, a
    complication arises: in that case, some subsets of $S$ are too wild and
    untameable for us to treat them mathematically as ``events''. Resolving
    that issue requires introducing measure theory, which is beyond the scope
    of this class, so we will ignore it and simply steer clear of any setting
    where any issues might arise.}

  In the dice-rolling example, the set of all possible events is
  $\left\{E: E\subseteq \left\{1,2,3,4,5,6\right\} \right\}$. 
  
  \begin{equation*}
    \begin{aligned}
      A &= [\text{observe an odd number}] = \{1,3,5\} \\
      B &= [\text{observe an even number}] = \{2,4,6\} \\
      C &= [\text{observe a number less than 5}] = \{1,2,3,4\} \\
      D &= [\text{observe a 2 or a 3}] = \{2,3\}\\
      E_1 &= [\text{observe a 1}] = \{1\}
    \end{aligned}
    \qquad
    \begin{aligned}
      E_2 &= [\text{observe a 2}] = \{2\} \\
      E_3 &= [\text{observe a 3}] = \{3\} \\
      E_4 &= [\text{observe a 4}] = \{4\} \\
      E_5 &= [\text{observe a 5}] = \{5\} \\
      E_6 &= [\text{observe a 6}] = \{6\}
    \end{aligned}
  \end{equation*}

  \item Some observations about events:
  \begin{itemize}
    \item The sample points are \textit{elements} of $S$. The simple events are
    \textit{singleton subsets} of $S$. In the dice example, we have:
    \begin{itemize}
      \item Sample points: 1,2,3,4,5,6.
      \item Simple events: $\left\{1\right\},\left\{2\right\},\left\{3\right\},\left\{4\right\},\left\{5\right\},\left\{6\right\}$.
    \end{itemize}
    \item The empty set $\emptyset$ and the whole sample space $S$ are always
    both events: $\emptyset$ is the event ``nothing happens'' and $S$ is the
    event ``something happens''.
    \item Events satisfy the properties of a boolean algebra:
    \begin{itemize}
      \item \textbf{``And'':} If $E$ and $F$ are events, then $E\cap F$ is the
      event that $E$ and $F$ occur.
      \item \textbf{``Or'':} If $E$ and $F$ are events, then $E\cup F$ is the
      event that $E$ or $F$ occurs.
      \item \textbf{``Not'':} If $E$ is an event, then $E^{c}= S\backslash E$
      is the event that $E$ does not occur.
    \end{itemize}
  \end{itemize}
  \item Two events $E$ and $F$ are \demph{mutually exclusive} if
  $E\cap F =\emptyset$. This means that $E$ and $F$ cannot both happen at the
  same time.

  In the dice example, the events $A$ and $B$ are mutually exclusive, since
  the dice roll cannot be both even and odd. But $A$ and $C$ are not mutually
  exclusive because $A\cap C =\left\{1,3\right\}\neq \emptyset$. If a 1 or a 3
  is rolled, then both $A$ and $C$ occur.
\end{itemize}

\subsubsection{Definition of probability measure}
\begin{definition}[Probability measure]
  Let $S$ be a sample space associated with an experiment. A function $\P$ is
  said to be a \demph{probability measure} on $S$ if it satisfies the
  following three axioms:
  \begin{enumerate}[label=\textbf{A.\arabic*}]
    \item (Nonnegativity) \label{item:probability-axiom-nonnegativity} For
    every event $E\subseteq S$,
    \begin{equation*}
      \P\left[E\right] \geq 0.
    \end{equation*}
    \item (Total mass one) $\P\left[S \right] =1$.
    \item (Countable additivity) If $E_{1},E_{2},\ldots$ is a sequence of
    events which are pairwise mutually exclusive (meaning
    $E_{i}\cap E_{j}=\emptyset$ if $i\neq j$), then
    \begin{equation*}
      \P\left[E_{1}\cup E_{2}\cup \ldots \right] = \sum_{i=1}^{\infty} \P\left[E_{i} \right].
    \end{equation*}
  \end{enumerate}
  If $\P$ is a probability measure, then for every event $E\subseteq S$, the
  number $\P\left[E \right]$ is called the \demph{probability} of $E$.
\end{definition}

The above definition only tells us the conditions an assignment of
probabilities must satisfy; it doesn't tell us how to assign specific
propabilities to events.

Probability measures satisfy some basic properties:

\begin{proposition}[Basic properties of probability measure]
  \label{prop:some-deductions-from-axioms}
  If $\P$ is a probability measure, then the following properties hold:
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item (The null event has probability zero) \label{item:empty-set-has-prob-zero}
    $\P\left[\emptyset \right] = 0$.
    \item (Finite additivity) \label{item:finite-additivity} Let $\left\{E_{1},\ldots,E_{n}\right\}$ be a
    \textit{finite} sequence of events. If the sequence is pairwise disjoint, then
    \begin{equation*}
      \P\left[E_{1}\cup E_{2}\cup\ldots\cup E_{n} \right] 
      = \P\left[E_{1} \right]+\P\left[E_{2} \right]+\ldots+\P\left[E_{n} \right].
    \end{equation*}
    \item (``With probability one, an event $E$ either does occur or doesn't'') \label{item:complements} $\P\left[E^{c} \right] = 1-\P\left[E \right]$.
    \item (Excision Property) \label{item:excision-property} If $A,B$ are events and $A\subseteq B$, then
    \begin{equation*}
      \P\left[B\backslash A \right] = \P\left[B \right] - \P\left[A \right].
    \end{equation*}
    \item (``The particular is less likely than the general'') \label{item:subsets} If $A,B$ are events and $A\subseteq B$, then
    $\P\left[ A\right] \leq \P\left[B \right]$.
    \item (``Probabilities are between 0 and 1'') \label{item:probabilities-are-in-unit-interval} For any event $E$,  $\P\left[E \right]\in [0,1]$.
  \end{enumerate}
\end{proposition}

\section{2026-01-14 | Week 01 | Lecture 02}
\begin{center}
  \begin{tcolorbox}[width=0.9\textwidth, colback=white, colframe=black]
    \textit{\textbf{The topic of this lecture:} independent events, conditional
      probabilities, random variables}
  \end{tcolorbox}
\end{center}

\subsection{Independent events and conditional probabilities}
\textit{This section is based on section 2.7 in the textbook.}

\begin{definition}[Independence]
  \label{def:independence}
  Two events $A$ and $B$ are said to be \demph{independent} if $\P\left[A\cap
    B \right] = \P\left[A \right] \P\left[B \right]$. Otherwise, the events
  are said to be dependent.
\end{definition}

\begin{definition}[Conditional probability]
  Let $A,B$ be events, and assume that $\P\left[B\right]>0$. Then the
  \demph{conditional probability of $A$, given $B$}, denoted
  $\P\left[A\mid B \right]$, is given by the formula
  \begin{equation*}
    \P\left[A\mid B \right] = \frac{\P\left[A\cap B \right]}{\P\left[B \right]}.
  \end{equation*}
\end{definition}

\fl{Interpretation:} $\P\left[A\mid B \right]$ is the probability of $A$ when
we know that event $B$ happened.

\begin{definition}
  \label{def:positive-relationship}
  We say that there exists a \demph{positive relationship} between events $A$
  and $B$ if
  \begin{equation*}
    \P\left[A\mid B \right]> \P\left[A \right],
  \end{equation*}
  and a \demph{negative relationship} if
  \begin{equation*}
    \P\left[A\mid B \right]< \P\left[A \right].
  \end{equation*}
\end{definition}

\begin{remark}
  Note the the conditions of \cref{def:positive-relationship} are symmetric in
  the sense that
  \begin{equation*}
    \P\left[A\mid B \right]> \P\left[A \right] \iff \P\left[B\mid A \right]>
    \P\left[B \right],
  \end{equation*}
  provided that both $A$ and $B$ have positive probability.
\end{remark}

\begin{example}
  Roll a 6-sided dice. Let $A$ be the event that a `2' was rolled, and $B$ be
  the event that an even number was observed.

  \begin{itemize}
    \item The unconditional probability: $\P\left[A \right]=1/6$.
    \item The conditional probability: $\P\left[A\mid B \right] = 1/3$.
  \end{itemize}
  Since $\frac{1}{3}>\frac{1}{6}$, we conclude there is a positive
  relationship between rolling a `2' and rolling an even number.
\end{example}

The notion of independence formalizes the idea of ``no relationship''.

\begin{proposition}
  \label{prop:independence-interpretation}
  If $A,B$ are events with positive probabilities then the following are
  equivalent:
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item $A$ and $B$ are independent.
    \item $\P\left[A\mid B \right] = \P\left[A \right]$
    and $\P\left[B\mid A \right] = \P\left[B \right]$.
  \end{enumerate}
\end{proposition}
In words, independence means that the probabilities of each event are
unaffected by whether or not the other event occurs.
\cref{prop:independence-interpretation} simply formalizes this idea using
conditional probabilities.


\subsection{Random variables}
\textit{Based on Sections 2.11, 4.2 in the textbook}


\begin{definition}[Random variable]
  A \demph{random variable} (or \demph{rv}) is a real-valued function whose domain is a sample
  space.
\end{definition}

The value of a random variable is thought of as varying depending on the
outcome of the experiment (the sample point). Random variables are usually
denoted with capital letters, like $X,Y,Z$.

\begin{example}[Sum 2d4]
  \label{ex:sum-2d4}
  Roll a 4-sided dice twice (this is the \textbf{experiment}). There are 16 possible
  \textbf{outcomes}. The \textbf{sample space} is
  \begin{equation*}
    S = \left\{(x,y): x,y\in \left\{1,2,3,4\right\} \right\}.
  \end{equation*}
  Let $X$ be the sum of the two rolls. We can represent $X$ by the following table:
  \begin{equation*}
    \begin{array}{c@{\quad}c|cccc} & \multicolumn{5}{c}{\text{Dice 2}} \\ & &
      1 & 2 & 3 & 4 \\ \cline{2-6}  & 1 & 2 & 3 & 4 & 5 \\ \text{Dice 1} & 2 & 3 & 4 & 5 & 6 \\ & 3 & 4 & 5 & 6 & 7 \\ & 4 & 5 & 6 & 7 & 8 \end{array}
  \end{equation*}
  \textbf{Events} are often defined using preimages of random variables. For
  example, the event that $X=6$ is:
  \begin{align*}
    [X=6] 
    &= \left\{\omega\in S: X(\omega) = 6\right\} \\
    &= \left\{(1,5), (2,4), (3,3), (4,2), (5,1)\right\}.
  \end{align*}
  The textbook uses the notation $\left\{X=6\right\}$ instead of
  $\left[ X=6 \right]$.

  Here's another example of an event. Let $E = \left\{2,4,6,8\right\}$. Then
  \begin{align*}
    \left[ X \text{ is even} \right]
    &= \left[ X \in E \right]\\
    &= \left\{\omega\in S: X(\omega) \in E \right\} \\
    &= \left\{(1,1), (1,3), (2,2), (2,4), (3,1), (3,3), (4,2), (4,4) \right\}.
  \end{align*}

  When writing random variables, we usually suppress the arguments, e.g.,
  writing $X$ rather than $X(\omega)$.
\end{example}
% \begin{example}
%   Consider an experiment in which we flip a coin twice. The sample space is
%   consists of four sample points:
%   \begin{equation*}
%     E_{1} = HH, \quad E_{2}= HT, \quad E_{3} = TH, \quad E_{4} = TT
%   \end{equation*}
%   Let $Y$ be the number of heads flipped. So $Y$ can take three values: $0,1$
%   and $2$. These are examples of events:
%   \begin{equation*}
%     \left[ Y=0 \right] = \left\{E_{4}\right\},
%     \quad \left[ Y=1 \right] = \left\{E_{2},E_{3}\right\},
%     \quad \text{and} \quad  \left[ Y=2 \right] = \left\{E_{1}\right\}.    
%   \end{equation*}
%   We can compute the probabilities of these:
%   \begin{equation*}
%     \P\left[Y=0 \right] = \P\left[E_{4} \right] = 1/4.
%   \end{equation*}
%   and
%   \begin{equation*}
%     \P\left[Y=1 \right] = \P\left[E_{2} \right]+ \P\left[E_{3} \right] = 1/4+1/4 = 1/2.
%   \end{equation*}
% \end{example}

% \begin{definition}[Support]
%   Let $X$ be a random variable. The \demph{support} of $X$, denoted
%   $\text{supp}(X)$ or $S_{X}$, is the smallest closed set $F\subseteq \R$ such
%   that $\P\left[X\in F \right]=1$.
% \end{definition}
% Informally, the support of a random variable is the set of all possible values
% that it can take. In \cref{ex:sum-2d4},
% $\text{supp}(X)= \left\{2,3,4,5,6,7,8\right\}$.
\newpage

\section{2026-01-16 | Week 01 | Lecture 03}

\subsection{Random variables}
\subsubsection{Discrete vs continuous}
\begin{definition}[Discrete random variable]
  \label{def:discrete-random-variable}
  We say that a random variable $X$ is a \demph{discrete random variable} if
  it can assume only a finite or countably infinite number of distinct values.
\end{definition}


\begin{definition}[Probability mass function, pmf]
  Let $X$ be a discrete random variable. The \demph{probability mass function}
  (or \demph{pmf}) of $X$ is the function
  \begin{equation*}
    p(x) = \P\left[X=x \right],
  \end{equation*}
  defined for every $x\in \R$.
\end{definition}

\begin{example}
  The pmf of $X$ in \cref{ex:sum-2d4} is
  \begin{equation*}
    p(2) = 1/16 \quad p(3) = 2/16, \quad p(4) = 3/16, \quad p(5) = 4/16, \quad p(6) = 3/16, \quad p(7)=2/16, \quad p(8) = 1/16
  \end{equation*}
  and $p(x)=0$ for all other $x\in \R$.
\end{example}


\begin{definition}[Distribution function - section 4.2]
  Let $X$ be any random variable. The \demph{cumulative distribution function}
  (or \demph{cdf}) of $X$ is the function
  \begin{equation*}
    F(x) = \P\left[X \leq x\right],
  \end{equation*}
  defined for all $x\in \R$.
\end{definition}

\begin{remark}
  The domain of a cdf is always $\R$, and it is always a nondecreasing
  function with $F(-\infty)=0$ and $F(+\infty)=1$. The cdf of a discrete
  random variable is always a step function.
\end{remark}

\begin{definition}[Continuous rv]
  \label{def:continuous-rv}
  Let $Y$ be a random variable with distribution function $F$. We say that $Y$
  is a \demph{continuous random variable} if there exists a nonnegative
  function $f$ such that
  \begin{equation}\label{eq:1}
    F(y) = \int_{-\infty}^{y}f(t)dt
  \end{equation}
  for all $y\in \R$. The function $f$ is called the \demph{probability density
    function} (or \demph{pdf}) of $Y$.
\end{definition}


\begin{remark}
  For continuous random variables, the distribution function $F$ is always
  continuous. Moreover, for a continuous random variable $Y$,
  $\P\left[Y=b \right]=0$ for all $b\in \R$.
  % \begin{equation*}
  %   \P\left[Y=b \right] 
  %   = \P\left[Y \leq b\right] - \lim_{a \to b^{-}}\P\left[Y \leq a\right] 
  %   = F(b) - \lim_{a \to b^{-}}F(a) = 0
  % \end{equation*}
  % where the last equality follows from continuity of $F$.
\end{remark}

\begin{theorem}[Theorem 4.3 in textbook]
  If $Y$ is a continuous random variable with pdf $f$, then
  \begin{equation*}
    \P\left[a \leq Y \leq b\right] = \int_{a}^{b}f(t)dt
  \end{equation*}
  for all $-\infty \leq a \leq b\leq +\infty$.
\end{theorem}
% \begin{proof}
%   \begin{equation*}
%     \P\left[a \leq Y \leq b\right] = \P\left[Y=a \right]+ \P\left[a<Y \leq b\right]
%   \end{equation*}
%   The result then follows from the following two computations:
%   \begin{align*}
%     \P\left[Y=a \right] = F(a) - F(a-) = \lim_{\epsilon \to 0} \int_{a-\epsilon}^{a}f(t)dt = 0,
%   \end{align*}
%   and
%   \begin{align*}
%     \P\left[a < Y \leq  b\right]
%     &= F(b) - F(a)\\
%     &= \int_{-\infty}^{b}f(t)dt - \int_{-\infty}^{a}f(t)dt\\ 
%     &= \int_{a}^{b}f(t)dt. 
%   \end{align*}
% \end{proof}

\subsubsection{Expected value}
\begin{definition}[Expectation of a continuous random variable]
  \label{def:expectation-continuous-random-variable}
  If $Y$ is a random variable with pdf $f$, then the \demph{expected value} of
  $Y$, denoted $\E\left[Y \right]$, is the quantity
  \begin{equation*}
    \E\left[ Y\right] = \int_{-\infty}^{\infty} y f(y)dy,
  \end{equation*}
  provided that $\int_{-\infty}^{\infty} |y|f(y)dy<\infty$. 
\end{definition}

\begin{remark}
  $\E\left[Y \right]$ is the long-run average of $Y$, if we were to repeat the
  experiment many times.
\end{remark}


\begin{theorem}[LOTUS - single variable case]
  \label{thm:law-unconscious-statistician}
  Let $g:\R \to \R$ be a function.
  \begin{enumerate}[label=\rm{(\roman*.)}]
    \item If $X$ has pmf $p$, then
    \begin{equation*}
      \E\left[g(X) \right]= \sum_{x\in \R:\ p(x)>0} g(x)p(x).
    \end{equation*}
    \item If $Y$ has pdf $f$, then
    \begin{equation*}
      \E\left[g(Y) \right] = \int_{-\infty}^{\infty}g(y)f(y)dy.
    \end{equation*}

  \end{enumerate}
\end{theorem}

\begin{remark}
  \label{rmk:need-for-joint-distn}
  Often we wish to compute probabilities of functions of multiple random
  variables, for example
  \begin{itemize}
    \item What is the probability that
    $\frac{X_{1}+\ldots+X_{n}}{n}\in (0,1)$? Here, the function is
    $g(x_{1},\ldots,x_{n})= \frac{x_{1}+\ldots+x_{n}}{n}$.
    \item What is the probability that $\max(X,Y) \leq 10$? Here the function is
    $g(x,y)=\max(x,y) $
    \item Suppose we roll two dice and take the maximum. What is the expected
    value? In this case, our dice rolls are $X,Y$ and we want to compute
    $\E\left[g(X,Y) \right]$, where $g(x,y) = \max(x,y)$.
    
  \end{itemize}
  To answer these sorts of questions, we need the notion of a ``joint distribution''.
\end{remark}

\subsubsection{Joint distributions}
\textit{Based on section 5.4 in the textbook. Everything in this section
  generalizes naturally to $n$ variables, but the results are simpler to state
  for just 2 random variables.}



\begin{definition}[Joint pmf]
  \label{def:joint-pmf}
  Let $X_{1}$ and $X_{2}$ be discrete random variables. The \demph{joint
    probability mass function} for $X_{1}$ and $X_{2}$ is the function
  \begin{equation*}
    p(x_{1},x_{2}) = \P\left[X_{1}=x_{1},X_{2}=x_{2} \right],
  \end{equation*}
  defined for all $x_{1},x_{2}\in \R$.
\end{definition}

\begin{definition}[Joint pdf]
  \label{def:joint-pdf}
  Let $X_{1}$ and $X_{2}$ be continuous random variables. We say that $X_{1}$ and $X_{2}$
  are \demph{jointly continuous} if there exists a function
  $f:\R^{2} \to \R_{ \geq 0}$ such that 
  \begin{equation*}
    \P\left[X_{1} \leq x_{1}, X_{2} \leq  x_{2}\right] =  \int_{-\infty}^{x_{1}}\int_{-\infty}^{x_{2}}    f(t_{1},t_{2}) dt_{2}dt_{1}.
  \end{equation*}
  for all $x_{1},x_{2}\in \R$. The function $f$ is called the \demph{joint probability
  density function} for $X_{1}$ and $X_{2}$.
\end{definition}


\begin{theorem}[LOTUS - multivariable case]
  \label{thm:lotus-multivariable-case}
  Let $g:\R^{2}\to \R$.
  \begin{itemize}
    \item   If $X_{1},X_{2}$ have joint pmf $p(x_{1},x_{2})$, then
    \begin{equation*}
      \E\left[g(X_{1},X_{2}) \right] = \sum_{\substack{(x_{1},x_{2})\in \R^{2}:\\ p(x_{1},x_{2})>0}} g(x_{1},x_{2})p(x_{1},x_{2}).
    \end{equation*}
    \item If $Y_{1},Y_{2}$ are jointly continuous random variables with joint
    pdf $f(y_{1},y_{2})$, then
    \begin{equation*}
      \E\left[g(Y_{1},Y_{2}) \right] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(y_{1},y_{2})f(y_{1},y_{2})dy_{1}dy_{2}.  
    \end{equation*}
  \end{itemize}
\end{theorem}

\begin{remark}
  \cref{thm:lotus-multivariable-case} generalizes to $n$ variables. It gives
  us a way to answer questions like those posed in
  \cref{rmk:need-for-joint-distn}.
\end{remark}

\newpage
\section{2026-01-21 | Week 02 | Lecture 04}
\subsection{Independence}
\subsubsection{Definition and characterization}
The aim of this section is to define what it means for random variables to be
independent.

\begin{definition}
  \label{def:independence-random-variables}
  We say that the random variables $X_{1},X_{2}$ are \demph{independent} if
  \begin{equation*}
    \P\left[X_{1}\leq x_{1},X_{2}\leq x_{2}\right] = \P\left[X_{1}\leq x_{1}\right] \P\left[X_{2}\leq x_{2}\right]
  \end{equation*}
  for all $x_{1},x_{2}\in \R$. 
\end{definition}

\begin{theorem}[Factorization theorem -- Theorem 5.4 in textbook]
  \label{thm:factorization-theorem}
  For discrete/continuous random variables, independence is equivalent to
  factorizability of the joint pmf/pdf. More formally, we have:
  
  \begin{itemize}
    \item \textbf{Discrete case:} Let $X_{1},X_{2}$ be discrete random
    variables with pmfs $p_{1},p_{2}$ and joint pmf $p$. Then $X_{1}$ and
    $X_{2}$ are independent if and only if
    \begin{equation*}
      p(x_{1},x_{2}) = p_{1}(x_{1})\cdot p_{2}(x_{2})
    \end{equation*}
    for all $x_{1},x_{2}\in \R$.
    \item \textbf{Continuous case:} Let $Y_{1}$ and $Y_{2}$ be continuous
    random variables with pdfs $f_{1}$ and $f_{2}$, and joint pdf
    $f$. Then $Y_{1}$ and $Y_{2}$ are independent if and only if
    \begin{equation*}
      f(y_{1},y_{2}) = f_{1}(y_{1}) \cdot f_{2}(y_{2})
    \end{equation*}
    for all $y_{1},y_{2}\in \R$.
  \end{itemize}
\end{theorem}

\begin{remark}
  \label{rmk:independence-intuition}
  If two random variables are independent, then observing one of them does not
  give any information about what value the other one takes.
\end{remark}



\begin{remark}
  In this course, we will frequently work with ``samples'' of $n$ independent
  random variables $X_{1},\ldots,X_{n}$. For that setting, note that
  \cref{def:joint-pmf,def:joint-pdf,def:independence-random-variables,thm:factorization-theorem}
  all generalize in the natural way (i.e., with $n$ variables rather than
  $2$). In that case, the intuition is that observing any number of them
  doesn't give you any information about the others.
\end{remark}

\subsubsection{Some useful consequences of independence}
\begin{theorem}
  If $X_{1}$ and $X_{2}$ are independent, then
  \begin{equation*}
    \E\left[X_{1}X_{2} \right] = \E\left[X_{1} \right] \E\left[X_{2} \right].
  \end{equation*}
\end{theorem}
\begin{proof}
  This can be proven for continuous/discrete random variables using
  \cref{thm:lotus-multivariable-case}.
\end{proof}


\begin{definition}[Variance of a random variable]
  If $X$ is a random variable and $\mu= \E\left[X \right]$, the
  \demph{variance} of $X$, denoted $V(X)$ or $\Var(X)$, is the quantity
  \begin{equation*}
    V(X) = \Var(X) = \E\left[(X-\mu)^{2} \right]
  \end{equation*}
  The positive square root of the variance is the \demph{standard deviation}
  of $X$. 
\end{definition}

\begin{theorem}
  If $X$ and $Y$ are independent random variables and $a$ are scalars, then
 \begin{equation*}
    \Var(X+Y) = \Var(X)+\Var(Y)
  \end{equation*}
  and
  \begin{equation*}
    \Var(aX+b) = a^{2}\Var(X).
  \end{equation*}
\end{theorem}

\newpage
\subsection{What is a statistic?}

Random sample is section 2.12.



A \demph{population} is a large body of data that is the target of our
interest. The subset collected from it is our \demph{sample}.

\textit{The objective of statistics to is to make an inference about a population
  based on information contained in a sample from that population and to provide
  an associated measure of goodness for the inference.}

\begin{definition}[Point Estimator]
  A \textbf{point estimator} is any function $W(X_{1},\ldots,X_{n})$ of a
  sample. Thus, any statistic is a point estimator. In general we refer to an
  \textit{estimator} as a function of the sample, while an \textit{estimate} is
  the realized value of an estimator (e.g., a number) that is obtained when a
  sample is actually taken.
\end{definition}


\begin{definition}[Statistic, Sampling Distribution]
  \label{def:statistic-sampling-distribution}
  Let $X_1,\ldots,X_n$ be a random sample of size $n$ from a population and let
  $T(x_1,\ldots,x_n)$ be a real-valued or vector-valued function whose domain
  includes the sample space of $(X_1,\ldots,X_n)$. Then the random variable or
  random vector
  \begin{equation*}
    Y\triangleq T(X_1,\ldots,X_n)
  \end{equation*}
  is called a \textbf{statistic}. The probability distribution of a statistic
  $Y$ is called the \textbf{sampling distribution} of $Y$.
\end{definition}
\begin{definition}[Sample Mean, Sample Variance]
  The \textbf{sample mean} is the statistic defined by
  \begin{equation*}
    \overline{X} \triangleq \frac{1}{n}\sum_{i=1}^{n}X_{i},
  \end{equation*}
  and the \textbf{sample variance} is the statistic defined by
  \begin{equation*}
    S^{2} \triangleq \frac{1}{n-1} \sum_{i=1}^{n} (X_{i}-\overline{X})^{2}.
  \end{equation*}
\end{definition}



\begin{theorem}[Chebychev's inequality]
  \label{thm:chebychevs-theorem}
  Let $Y$ be a random variable with mean $\mu$ and finite variance
  $\sigma^{2}$. Then for any constant $c>0$,
  \begin{equation*}
    \P\left[|Y-\mu| \geq c\right] \leq \frac{\sigma^{2}}{c^{2}}
  \end{equation*}
\end{theorem}



\end{document}